# ğŸ” AnÃ¡lisis de Sobreajuste (Overfitting) en XGBoost

**Fecha**: 18 de noviembre de 2025
**Modelo evaluado**: `models/xgb/completa_present_log_p2_1800_ELEGIDO/`

---

## ğŸ“Š MÃ©tricas del Modelo

### **TRAIN SET**
| MÃ©trica | Valor |
|---------|-------|
| **RMSE** | $8,586 |
| **MAE** | $6,090 |
| **MAPE** | 2.34% âœ… Excelente |
| **RÂ² Score** | 0.9947 âœ… Muy alto |

### **TEST SET**
| MÃ©trica | Valor |
|---------|-------|
| **RMSE** | $35,901 |
| **MAE** | $21,224 |
| **MAPE** | 7.20% âš ï¸ Moderado |
| **RÂ² Score** | 0.9304 âš ï¸ Bueno pero mÃ¡s bajo |

---

## ğŸš¨ DiagnÃ³stico de Sobreajuste

### **1. Brecha Train-Test (El Indicador Principal)**

```
MAPE Train â†’ Test:    2.34% â†’ 7.20%  (RATIO: 3.08x) âš ï¸ PREOCUPANTE
MAE Train â†’ Test:     $6,090 â†’ $21,224 (RATIO: 3.48x) âš ï¸ PREOCUPANTE  
RÂ² Train â†’ Test:      0.9947 â†’ 0.9304 (DIFERENCIA: -6.43%) âš ï¸ MODERADO
RMSE Train â†’ Test:    $8,586 â†’ $35,901 (RATIO: 4.18x) âš ï¸ PREOCUPANTE
```

### **2. AsimetrÃ­a de Residuos (DistribuciÃ³n sospechosa)**

| MÃ©trica | Train | Test |
|---------|-------|------|
| **Skew** | 0.465 | 1.203 | â†‘ Aumenta en test |
| **Kurtosis** | 6.97 | 12.77 | â†‘ Colas muy pesadas en test |

**âš ï¸ InterpretaciÃ³n**: 
- El modelo aprende residuos **simÃ©tricos** en training
- En test, los residuos tienen **sesgo positivo** (predice mÃ¡s bajo de lo esperado en casos extremos)
- Las colas pesadas indican **outliers** no capturados en training

---

## ğŸ”§ HiperparÃ¡metros Actuales

```json
{
  "n_estimators": 1800,          â† ğŸ’° ALTO
  "learning_rate": 0.025,        â† CONSERVADOR
  "max_depth": 5,                â† CONSERVADOR
  "min_child_weight": 10,        â† CONSERVADOR
  "subsample": 0.7,              â† MODERADO
  "colsample_bytree": 0.7,       â† MODERADO
  "reg_lambda": 2.0,             â† MODERADO
  "reg_alpha": 0.0               â† NO HAY L1
}
```

### **AnÃ¡lisis de los hiperparÃ¡metros:**

âœ… **Bien calibrados**:
- `max_depth=5` â†’ Ãrboles bajos, reduce complejidad
- `min_child_weight=10` â†’ Evita split en nodos pequeÃ±os
- `learning_rate=0.025` â†’ Aprendizaje lento y controlado
- `reg_lambda=2.0` â†’ RegularizaciÃ³n L2

âš ï¸ **Posible problema**:
- **`n_estimators=1800`** es ALTO
- Con `learning_rate=0.025` bajo, 1800 Ã¡rboles puede estar capturando **ruido** en training
- El modelo tiene **capacidad para sobreajustar** aunque los hiperparÃ¡metros sean conservadores

---

## ğŸ“ˆ Indicadores de Sobreajuste

| Indicador | Valor | Severidad |
|-----------|-------|-----------|
| MAPE Gap (trainâ†’test) | 3.08x | **ğŸ”´ SEVERA** |
| MAE Gap (trainâ†’test) | 3.48x | **ğŸ”´ SEVERA** |
| RMSE Gap (trainâ†’test) | 4.18x | **ğŸ”´ SEVERA** |
| Kurtosis en test | 12.77 | **ğŸŸ¡ MODERADA** |
| RÂ² gap | -6.43pp | **ğŸŸ¡ MODERADA** |

---

## ğŸ¯ ConclusiÃ³n

### **SÃ, EL MODELO ESTÃ SOBREAJUSTANDO** âœ… Confirmado

**Evidencia:**
1. âœ… El MAPE en train es **3x mejor** que en test
2. âœ… El MAE se **multiplica por 3.5** en test
3. âœ… Los residuos en test tienen **distribuciÃ³n muy diferente** (mÃ¡s asimÃ©trica)
4. âœ… El modelo generaliza **menos bien** de lo que podrÃ­a

---

## ğŸ’¡ Recomendaciones de Mejora

### **OpciÃ³n 1: Reducir complejidad (RECOMENDADO)**
```python
# Reducir n_estimators
"n_estimators": 800,  # de 1800 (reducciÃ³n del 55%)

# O aumentar regularizaciÃ³n
"reg_lambda": 5.0,     # de 2.0 (aumento del 150%)
"reg_alpha": 0.5,      # agregar L1 (nuevo)

# O aumentar subsampling
"subsample": 0.5,      # de 0.7 (mayor variancia entre Ã¡rboles)
"colsample_bytree": 0.5, # de 0.7
```

### **OpciÃ³n 2: Early Stopping (IDEAL)**
```python
# Usar validaciÃ³n interna durante training
# Detener cuando validation MAPE deje de mejorar

model.fit(
    X_train, y_train,
    eval_set=[(X_val, y_val)],
    callbacks=[EarlyStopping(rounds=100, save_best=True)]
)
```

### **OpciÃ³n 3: Cross-Validation + Ensemble**
```python
# Entrenar mÃºltiples modelos con diferentes random_states
# Promediar predicciones para mejor generalizaciÃ³n
```

---

## ğŸ“‹ Plan de AcciÃ³n Sugerido

### **Paso 1: Ajuste RÃ¡pido (10 min)**
- Reducir `n_estimators` de 1800 a 1000
- Aumentar `reg_lambda` de 2.0 a 4.0
- Entrenar y comparar test MAPE

### **Paso 2: Early Stopping (30 min)**
- Implementar validaciÃ³n interna
- Dejar que XGBoost auto-ajuste el nÃºmero de Ã¡rboles
- Esperar reducciÃ³n en test MAPE de ~1-2%

### **Paso 3: ValidaciÃ³n Cruzada (1 hora)**
- Entrenar con 5-fold CV
- Reportar media y desviaciÃ³n estÃ¡ndar de MAPE
- Verificar que gap train-test sea < 1.5x

---

## ğŸ”— Archivos Relevantes

- MÃ©tricas actuales: `models/xgb/completa_present_log_p2_1800_ELEGIDO/metrics.json`
- Meta del modelo: `models/xgb/completa_present_log_p2_1800_ELEGIDO/meta.json`
- Script de entrenamiento: `src/train_xgb_es.py` (usa early stopping)
- Diagnostico: `diagnostic_regression_vs_xgb.py`

---

## ğŸ“ Notas

1. **El modelo NO es malo**: RÂ² de 0.93 en test es bueno
2. **Pero hay potencial de mejora**: Reducir el gap train-test aumentarÃ­a confiabilidad
3. **Early stopping es tu amigo**: El script `train_xgb_es.py` ya lo implementa
4. **Considera el trade-off**: Mejor generalizaciÃ³n vs. menor precisiÃ³n en training

---

