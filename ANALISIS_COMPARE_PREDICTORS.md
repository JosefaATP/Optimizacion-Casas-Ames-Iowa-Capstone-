# AN√ÅLISIS: `scripts/compare_predictors.py` - Integraci√≥n con run_opt.py

**Documento de an√°lisis y gu√≠a de integraci√≥n**

---

## üìã ¬øQU√â HACE `compare_predictors.py`?

El script compara **2 modelos de predicci√≥n de precio** sobre una casa remodelada:

1. **XGBoost** (modelo productivo)
2. **Regresi√≥n Linear** (modelo base del equipo anterior)

La idea es validar que XGBoost predice mejor que la regresi√≥n antigua.

---

## üîç AN√ÅLISIS L√çNEA POR L√çNEA

### Modos de Operaci√≥n

```python
# Modo 1: Resolver el MIP + Comparar
python scripts/compare_predictors.py --pid 526301100 --budget 80000 --reg-model models/baseline.joblib

# Modo 2: Usar casa remodelada precalculada + Comparar (sin resolver MIP)
python scripts/compare_predictors.py --pid 526301100 --xin-csv X_input_after_opt.csv --reg-model models/baseline.joblib
```

**Diferencia:**
- Modo 1: Resuelve la optimizaci√≥n (lento) y luego compara
- Modo 2: Carga casa ya optimizada de un CSV (r√°pido)

---

### Step 1: Cargar Insumos (l√≠neas 35-41)

```python
base = get_base_house(pid)           # Lee base_house.csv con PID
base_row = base.row
ct = costs.CostTables()              # Tablas de costos (cocina, exterior, etc.)
bundle = XGBBundle()                 # Carga modelo XGBoost productivo

# Precio base: intenta CSV de regresi√≥n, sino usa XGB
precio_base = _precio_base_from_csv(pid)
if precio_base is None:
    X_base = build_base_input_row(bundle, base_row)
    precio_base = float(bundle.predict(X_base).iloc[0])  # XGB predice
```

**Lo que pasa:**
- Lee la casa base del CSV
- Obtiene el precio original (SalePrice_Present o SalePrice del CSV)
- Si no lo encuentra, usa XGBoost para predecir el precio actual

---

### Step 2: Decisi√≥n - Resolver MIP o Cargar CSV (l√≠neas 53-74)

```python
if xin_csv:
    # MODO 2: Cargar casa √≥ptima del CSV (saltea el MIP)
    X_in = _load_x_input_from_csv(xin_csv)
    m = None
else:
    # MODO 1: Resolver el MIP (caro computacionalmente)
    m = build_mip_embed(base_row, budget, ct, bundle, base_price=precio_base)
    m.Params.TimeLimit = time_limit
    m.optimize()  # ‚Üê Aqu√≠ se resuelve la optimizaci√≥n
    X_in = rebuild_embed_input_df(m, m._X_base_numeric)  # Reconstruir fila √≥ptima
```

**La l√≥gica:**
- Si pasas `--xin-csv`: saltas resolver el MIP (r√°pido)
- Si pasas `--budget`: resuelves el MIP (completo pero lento)

---

### Step 3: Predicciones (l√≠neas 76-140)

```python
# 1. Precio XGBoost
precio_xgb = float(bundle.predict(X_in).iloc[0])

# 2. Cargar modelo de regresi√≥n
reg_model = joblib.load(reg_model_path)

# 3. Preparar fila para regresi√≥n (alineaci√≥n de columnas)
reg_cols = list(getattr(reg_model, "feature_names_in_", []))
# ... c√≥digo complejo para alinear nombres de columnas ...
X_reg = pd.DataFrame([new_row], columns=reg_cols)

# 4. Precio Regresi√≥n
reg_pred = reg_model.predict(X_reg)
precio_reg = float(np.exp(reg_pred[0]))  # ‚Üê Deslogaritmo
```

**Lo que pasa:**

| Paso | Acci√≥n | Resultado |
|------|--------|-----------|
| 1 | XGBoost predice sobre casa remodelada | `precio_xgb` |
| 2 | Carga modelo regresi√≥n del joblib | `reg_model` |
| 3 | Alinea columnas (XGB != Regresi√≥n) | `X_reg` con columnas correctas |
| 4 | Regresi√≥n predice (modelo entrenado en log) | `precio_reg` (exponenciado) |

---

### Step 4: Chequeos de Validez (l√≠neas 142-155)

```python
# Verifica que la soluci√≥n sea factible
if m is not None:
    max_slack = max(abs(c.Slack) for c in m.getConstrs())
    if max_slack > 1e-3:
        raise RuntimeError(f"Soluci√≥n infactible!")
    
    # Verifica que el precio no baje
    y_price_opt = float(m._y_price_var.X)
    if y_price_opt < precio_base - 1e-3:
        raise RuntimeError(f"Precio baja el original!")
```

**Seguridad:**
- Si la soluci√≥n tiene restricciones violadas ‚Üí ERROR
- Si la casa "baja de precio" ‚Üí ERROR (no tiene sentido una remodelaci√≥n que baja precio)

---

### Step 5: Comparaci√≥n e Impresi√≥n (l√≠neas 157-170)

```python
# Calcula diferencia porcentual
uplift_vs_reg = (precio_xgb - precio_reg) / precio_reg * 100

# Imprime resultados
print(f"Precio base (XGB):           ${precio_base:,.0f}")
print(f"Precio remodelado XGB:       ${precio_xgb:,.0f}")
print(f"Precio remodelado Regresi√≥n: ${precio_reg:,.0f}")
print(f"Diferencia % (XGB vs Reg):   {uplift_vs_reg:.2f}%")
```

**Output ejemplo:**
```
Precio base (XGB):           $195,000
Precio remodelado XGB:       $215,000
Precio remodelado Regresi√≥n: $208,500
Diferencia % (XGB vs Reg):   3.12%
```

---

## üîó FLUJO ACTUAL

```
run_opt.py (main)
    ‚îÇ
    ‚îú‚îÄ‚Üí Resuelve MIP
    ‚îÇ   ‚îî‚îÄ‚Üí Obtiene casa_remodelada
    ‚îÇ
    ‚îî‚îÄ‚Üí FIN (no compara predictores)


compare_predictors.py (script separado)
    ‚îÇ
    ‚îú‚îÄ‚Üí Resuelve MIP (o carga CSV)
    ‚îÇ   ‚îî‚îÄ‚Üí Obtiene casa_remodelada
    ‚îÇ
    ‚îú‚îÄ‚Üí XGBoost(casa_remodelada) ‚Üí precio_xgb
    ‚îú‚îÄ‚Üí Regresi√≥n(casa_remodelada) ‚Üí precio_reg
    ‚îÇ
    ‚îî‚îÄ‚Üí Compara e imprime diferencia
```

**Problema:** Son **2 scripts separados** que resuelven el MIP de forma independiente

---

## üí° OPCI√ìN 1: Integraci√≥n Directa en run_opt.py (RECOMENDADO)

Agregar la comparaci√≥n de predictores **al final de run_opt.py**, justo despu√©s de imprimir resultados.

### Modificaci√≥n Propuesta

**En `run_opt.py` despu√©s de la l√≠nea 1387 (FIN RESULTADOS), agregar:**

```python
# ============================================
# COMPARAR PREDICTORES (XGBoost vs Regresi√≥n)
# ============================================

try:
    import joblib
    from optimization.remodel.run_opt import rebuild_embed_input_df
    
    print("\n" + "="*80)
    print("COMPARACI√ìN: XGBoost vs Regresi√≥n Base")
    print("="*80)
    
    # 1. Precio base
    precio_base = float(m._y_base_var.X) if hasattr(m, '_y_base_var') else None
    if precio_base is None:
        X_base = build_base_input_row(bundle, base_row)
        precio_base = float(bundle.predict(X_base).iloc[0])
    
    # 2. Casa remodelada ya resuelta
    X_opt = rebuild_embed_input_df(m, m._X_base_numeric)
    
    # 3. XGBoost prediction
    precio_xgb = float(bundle.predict(X_opt).iloc[0])
    
    # 4. Regresi√≥n prediction (si existe el modelo)
    try:
        # Buscar modelo de regresi√≥n
        reg_paths = [
            "models/reg/regresion_base.joblib",
            "models/baseline.joblib",
            "models/regresion.joblib"
        ]
        reg_model = None
        for path in reg_paths:
            if os.path.exists(path):
                reg_model = joblib.load(path)
                break
        
        if reg_model:
            # Alinear columnas con regresi√≥n
            reg_cols = list(getattr(reg_model, "feature_names_in_", []))
            if reg_cols:
                try:
                    df_reg = pd.read_csv("data/raw/df_final_regresion.csv")
                    df_reg.columns = [c.replace("\ufeff", "").strip() for c in df_reg.columns]
                    row_reg = df_reg.loc[df_reg["PID"] == args.pid].iloc[0]
                except:
                    row_reg = pd.Series({c: base_row.get(c, np.nan) for c in reg_cols})
                
                # Construir X_reg alineada
                new_row = {}
                for c in reg_cols:
                    if c in X_opt.columns:
                        new_row[c] = float(X_opt[c].iloc[0])
                    else:
                        new_row[c] = row_reg.get(c, np.nan)
                X_reg = pd.DataFrame([new_row], columns=reg_cols)
                
                # Predecir con regresi√≥n
                reg_pred = float(reg_model.predict(X_reg)[0])
                precio_reg = np.exp(reg_pred) if reg_pred < 50 else reg_pred  # Deslogaritmo si necesario
                
                # Comparaci√≥n
                diff_absoluta = precio_xgb - precio_reg
                diff_porcentaje = (diff_absoluta / precio_reg * 100) if precio_reg > 0 else np.nan
                uplift_xgb = (precio_xgb - precio_base) / precio_base * 100
                uplift_reg = (precio_reg - precio_base) / precio_base * 100
                
                print(f"\nüí∞ COMPARACI√ìN DE PREDICTORES:")
                print(f"  Precio base (actual):        ${precio_base:,.0f}")
                print(f"  Precio remodelado (XGBoost): ${precio_xgb:,.0f}  (+{uplift_xgb:.1f}%)")
                print(f"  Precio remodelado (Regresi√≥n): ${precio_reg:,.0f}  (+{uplift_reg:.1f}%)")
                print(f"\n  üìä Diferencia XGBoost vs Regresi√≥n:")
                print(f"     Absoluta: ${diff_absoluta:,.0f}")
                print(f"     Porcentaje: {diff_porcentaje:.2f}%")
                
                if diff_porcentaje > 0:
                    print(f"\n  ‚úÖ XGBoost SUPERA a Regresi√≥n por {diff_porcentaje:.2f}%")
                else:
                    print(f"\n  ‚ö†Ô∏è  Regresi√≥n SUPERA a XGBoost por {abs(diff_porcentaje):.2f}%")
        else:
            print("\n‚ö†Ô∏è  No se encontr√≥ modelo de regresi√≥n. Saltando comparaci√≥n.")
    
    except Exception as e:
        print(f"\n‚ö†Ô∏è  Error al comparar predictores: {e}")

except Exception as e:
    print(f"\n‚ö†Ô∏è  Error en secci√≥n de comparaci√≥n: {e}")
```

---

## üí° OPCI√ìN 2: Mantener Script Separado (Actual)

Ejecutar en 2 pasos:

```bash
# Paso 1: Optimizar
python3 optimization/remodel/run_opt.py --pid 526301100 --budget 80000

# Paso 2: Comparar predictores
python3 scripts/compare_predictors.py --pid 526301100 --budget 80000 --reg-model models/reg/regresion_base.joblib
```

**Ventajas:**
- Scripts modulares
- No aumenta tama√±o de run_opt.py

**Desventajas:**
- Resuelve el MIP 2 veces (lento)
- El usuario debe ejecutar 2 comandos

---

## üí° OPCI√ìN 3: Usar compare_predictors con CSV (MEJOR SI QUIERES RAPIDEZ)

```bash
# Paso 1: Optimizar y guardar X_opt a CSV
python3 optimization/remodel/run_opt.py --pid 526301100 --budget 80000 --output-csv X_input_after_opt.csv

# Paso 2: Comparar (sin resolver MIP otra vez)
python3 scripts/compare_predictors.py --pid 526301100 --xin-csv X_input_after_opt.csv --reg-model models/reg/regresion_base.joblib
```

**Ventajas:**
- Resuelve MIP 1 sola vez
- R√°pido (no replica c√°lculos)
- Modular

**Desventajas:**
- Requiere guardar CSV intermedio

---

## üéØ MI RECOMENDACI√ìN

**OPCI√ìN 1: Integraci√≥n Directa en run_opt.py**

**Razones:**
1. ‚úÖ El usuario ve TODO en 1 ejecuci√≥n
2. ‚úÖ No replica c√°lculos (MIP se resuelve 1 sola vez)
3. ‚úÖ Output integral: optimizaci√≥n + comparaci√≥n de predictores
4. ‚úÖ Listo para presentar en Capstone

**C√≥digo a agregar:**
- Aproximadamente 80-100 l√≠neas al final de run_opt.py
- Reutiliza funciones ya existentes (no c√≥digo nuevo)
- Maneja excepciones si modelo regresi√≥n no existe

---

## üìä OUTPUT ESPERADO AL FINAL DE run_opt.py

```
================================================================================
            FIN RESULTADOS DE LA OPTIMIZACI√ìN
================================================================================

================================================================================
COMPARACI√ìN: XGBoost vs Regresi√≥n Base
================================================================================

üí∞ COMPARACI√ìN DE PREDICTORES:
  Precio base (actual):        $195,000
  Precio remodelado (XGBoost): $215,000  (+10.3%)
  Precio remodelado (Regresi√≥n): $208,500  (+6.9%)

  üìä Diferencia XGBoost vs Regresi√≥n:
     Absoluta: $6,500
     Porcentaje: 3.12%

  ‚úÖ XGBoost SUPERA a Regresi√≥n por 3.12%
```

---

## üîß ARCHIVOS A MODIFICAR

### 1. `optimization/remodel/run_opt.py`
- Agregar import al inicio: `import joblib, os`
- Agregar secci√≥n de comparaci√≥n al final (antes del `if __name__ == "__main__"`)

### 2. Opcional: `optimization/remodel/run_opt.py` (par√°metro)
- Agregar `--skip-compare` para saltear comparaci√≥n si quieres rapidez

### 3. Opcional: `scripts/compare_predictors.py`
- Ahora ser√≠a "respaldo" para comparaciones puntuales

---

## üìã CHECKLIST

- [ ] Revisar d√≥nde est√° el modelo de regresi√≥n en tu estructura
- [ ] Confirmar path a `models/reg/regresion_base.joblib` (o similar)
- [ ] Agregar imports necesarios a run_opt.py
- [ ] Agregar secci√≥n de comparaci√≥n
- [ ] Validar que `build_base_input_row` funciona correctamente
- [ ] Probar con 1 house (ej. PID 526301100)
- [ ] Verificar que output se ve claro y correcto

---

**¬øQuieres que implemente la Opci√≥n 1 ahora?**

