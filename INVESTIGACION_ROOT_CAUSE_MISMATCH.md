# INVESTIGACI√ìN PROFUNDA: El Verdadero Problema del Mismatch 13.4%

## 1. Contexto del Hallazgo

**Descubrimiento clave:** El "fix" de threshold boundary (`thr - 1e-8`) **ya estaba en el c√≥digo** cuando lo revisamos, pero el mismatch persiste.

- Propiedad 528328100 con budget 250000:
  - y_log(MIP) = 13.372293
  - y_log(externa/correcta) = 13.238561
  - **Œî = 0.133733 (13.4% - exactamente igual al bug reportado)**

## 2. Hip√≥tesis Investigadas

### ‚ùå Hypothesis 1: Threshold Boundary Issue
**Status:** REFUTADO
- La correcci√≥n (`thr - 1e-8`) ya estaba en el c√≥digo en el commit original
- A pesar de estar presente, el mismatch persiste
- **Conclusi√≥n:** No es el problema principal

## 3. √Åreas de Investigaci√≥n Activas

### üîç √Årea A: Base Score
**Archivo:** `optimization/remodel/xgb_predictor.py`, l√≠neas 549-565

```python
if (self.b0_offset is None) or (abs(self.b0_offset) < 1e-12):
    try:
        bs_attr = bst.attr("base_score")
        if bs_attr is not None:
            self.b0_offset = float(bs_attr)
        else:
            # fallback: eval√∫a predict(output_margin) en el origen y resta suma de hojas
            import numpy as _np
            zeros = _np.zeros((1, len(x_list)))
            y_out = float(self.reg.predict(zeros, output_margin=True)[0])
            y_in = self._eval_sum_leaves(zeros.ravel())
            self.b0_offset = float(y_out - y_in)
    except Exception:
        self.b0_offset = 0.0
```

**Problemas potenciales:**
1. ¬øSe obtiene correctamente el base_score del booster?
2. ¬øCu√°ndo se ejecuta este c√≥digo? (una sola vez? cada vez?)
3. ¬øSe preserva b0_offset entre llamadas?
4. ¬øLa selecci√≥n de `len(x_list)` es correcta? (deber√≠a ser el n√∫mero de features)

**Investigar:**
- Verificar que `bst.attr("base_score")` devuelve el valor correcto
- Comprobar si b0_offset se actualiza correctamente en el MIP
- ¬øSe aplica b0_offset al constraint de y_log?

### üîç √Årea B: Suma de Hojas
**Archivo:** `optimization/remodel/xgb_predictor.py`, l√≠nea 700

```python
total_expr += gp.quicksum(z[k] * leaves[k][1] for k in range(len(leaves)))
```

**Problemas potenciales:**
1. ¬øLos valores `leaves[k][1]` se extraen correctamente?
2. ¬øSe redondean o truncan num√©ricamente?
3. ¬øHay acumulaci√≥n de errores con 914 √°rboles?

**Investigar:**
- Verificar precisi√≥n de los valores de hojas: ¬øTienen suficientes decimales?
- Comparar suma manual vs suma en MIP
- Revisar si hay p√©rdida de precisi√≥n con `gp.quicksum()`

### üîç √Årea C: Constraint de y_log
**Archivo:** `optimization/remodel/xgb_predictor.py`, l√≠nea 703

```python
m.addConstr(y_log == total_expr, name="YLOG_XGB_SUM")
```

**Problemas potenciales:**
1. ¬øEs una igualdad estricta o tiene tolerancia?
2. ¬øGurobi cumple exactamente con `y_log == total_expr` o tiene tolerancia num√©rica?
3. ¬øSe considera el base_score aqu√≠?

**Investigar:**
- Verificar que `total_expr` incluye base_score
- ¬øDeber√≠a ser `y_log == total_expr + b0_offset`?
- Revisar la tolerancia num√©rica de Gurobi (FeasibilityTol=1e-7)

### üîç √Årea D: Selecci√≥n de Hojas
**Archivo:** `optimization/remodel/xgb_predictor.py`, l√≠neas 657-697

```python
m.addConstr(xv <= thr - 1e-8 + M_le * (1 - z[k]), name=f"T{t_idx}_L{k}_f{f_idx}_lt")
m.addConstr(xv >= thr - M_ge * (1 - z[k]), name=f"T{t_idx}_R{k}_f{f_idx}_ge")
```

**Problemas potenciales:**
1. ¬øLa l√≥gica Big-M funciona correctamente con Gurobi?
2. ¬øHay conflictos con m√∫ltiples constraints simult√°neamente activos?
3. ¬øHay soluciones NO √≥ptimas pero factibles que el solver elige?

**Investigar:**
- Verificar que una sola hoja se selecciona por √°rbol (one-hot constraint)
- Comprobar que cada √°rbol est√° correctamente desacoplado
- Ver si el gap de optimalidad es realmente 0.0%

### üîç √Årea E: Alineaci√≥n de Caracter√≠sticas
**Archivo:** M√∫ltiples localizaciones

**Problemas potenciales:**
1. ¬øLas caracter√≠sticas en el MIP est√°n en el mismo orden que en XGBoost?
2. ¬øHay problemas de normalizaci√≥n/escala?
3. ¬øSe transforman las caracter√≠sticas antes de pasarlas al MIP?

**Investigar:**
- Verificar que `x_list[f_idx]` en el MIP corresponde a la misma caracter√≠stica que en XGBoost
- Comprobar el orden de One-Hot Encoding
- Revisar transformaciones del preprocessor

## 4. Hip√≥tesis Principal: Base Score NO se Suma

**Mi intuici√≥n:** El problema es que `y_log = total_expr` DEBER√çA ser `y_log = total_expr + b0_offset`

**Razonamiento:**
- XGBoost predice: $\hat{y} = \sum_{i=1}^{914} \text{leaf}_i + \text{base\_score}$
- En el MIP: `total_expr = sum of selected leaves`
- El constraint es: `y_log == total_expr` (SIN base_score)
- Esto significa `y_log` NO incluye base_score, pero deber√≠a

**Comprobaci√≥n:**
- Si esto es correcto, entonces el mismatch ser√≠a aproximadamente igual a base_score
- base_score = 12.437748
- Mismatch = 0.133733
- Ratio: 0.133733 / 12.437748 = 0.0107 (1.07%)

Esto NO coincide. El base_score es ~12, pero el mismatch es solo 0.13. As√≠ que no es simplemente que falta el base_score.

## 5. Otra Posibilidad: Precision Num√©rica en Gurobi

**Problema:** Con 914 √°rboles √ó m√∫ltiples constraints, hay acumulaci√≥n de errores num√©ricos.

**Evidence:**
- Gurobi FeasibilityTol = 1e-7
- Tolerancia relativa probablemente es mayor
- Con 914 √°rboles, los errores se acumulan

**Investigar:**
- Ejecutar MIP sin optimizaci√≥n y ver qu√© valores toman z[k]
- Verificar que exactamente 1 z[k] = 1 y el resto = 0 para cada √°rbol
- Comparar la suma manual con el valor de y_log

## 6. HALLAZGO CR√çTICO: Doble C√°lculo de Base Score

**Descubrimiento:** El base_score se calcula DOS VECES en c√≥digo INCONSISTENTE:

### Primera Ubicaci√≥n (XGBBundle.__init__, l√≠neas 314-324)
```python
# Se extrae del JSON del modelo
self.b0_offset: float = 0.0
try:
    bst = self.reg.get_booster()
    json_model = bst.save_raw("json")
    data = json.loads(json_model)
    bs_str = data.get("learner", {}).get("learner_model_param", {}).get("base_score", "[0.5]")
    if isinstance(bs_str, str) and "[" in bs_str:
        m = re.match(r"\[\s*([0-9.eE+-]+)\s*\]", bs_str)
        if m:
            self.b0_offset = float(m.group(1))
    else:
        self.b0_offset = float(bs_str) if bs_str else 0.5
except Exception:
    self.b0_offset = 0.5  # fallback
```

### Segunda Ubicaci√≥n (attach_to_gurobi, l√≠neas 568-578)
```python
if (self.b0_offset is None) or (abs(self.b0_offset) < 1e-12):
    try:
        bs_attr = bst.attr("base_score")
        if bs_attr is not None:
            self.b0_offset = float(bs_attr)
        else:
            # fallback: eval√∫a predict(output_margin) en el origen...
            zeros = _np.zeros((1, len(x_list)))
            y_out = float(self.reg.predict(zeros, output_margin=True)[0])
            y_in = self._eval_sum_leaves(zeros.ravel())
            self.b0_offset = float(y_out - y_in)
    except Exception:
        self.b0_offset = 0.0
```

**Problema:** El segundo c√≥digo NUNCA se ejecuta porque el primero ya establece `b0_offset = 12.437748`, lo que NO es None ni cercano a cero.

### Application en gurobi_model.py (l√≠nea 1840)
```python
m.addConstr(y_log == y_log_raw + b0, name="YLOG_with_offset")
```

Donde `b0` se obtiene de:
```python
b0 = float(bundle.b0_offset if hasattr(bundle, "b0_offset") else 0.0)
```

**Implicaci√≥n:** El base_score est√° siendo usado, pero podr√≠a estar **mal calculado** en la primera ubicaci√≥n.

## 7. Hip√≥tesis Principal: Base Score Incorrecto

**Razonamiento:**
1. El m√©todo de extracci√≥n JSON con regex (`\[\s*([0-9.eE+-]+)\s*\]`) podr√≠a malinterpretar el valor
2. El formato puede haber cambiado en diferentes versiones de XGBoost
3. Los dos m√©todos usan fuentes diferentes:
   - M√©todo 1 (JSON): Posiblemente desactualizado
   - M√©todo 2 (attr): El m√©todo "oficial" de XGBoost

**Test Recomendado:** Ejecutar `investigate_base_score.py` para comparar:
- `b0_offset` almacenado vs calculado manualmente
- Si Œî > 1e-6, hemos encontrado el culpable

## 8. Plan de Acci√≥n Inmediato

### Paso 1: Ejecutar investigate_base_score.py
Ver si el base_score se calcula correctamente

### Paso 2: Si hay discrepancia en base_score
Corregir el c√°lculo en `__init__` para usar `bst.attr("base_score")` directamente

### Paso 3: Verificar constraint de y_log
Confirmar que en `gurobi_model.py` l√≠nea 1840 se aplica correctamente

### Paso 4: Debuggear selecci√≥n de hojas en MIP
Extraer z[k] despu√©s de resolver para verificar que se selecciona la hoja correcta por √°rbol

### Paso 5: An√°lisis de precisi√≥n num√©rica
Si los anteriores pasos no resuelven el problema, investigar:
- FeasibilityTol m√°s estricta
- Numerical Focus mayor

