# ğŸ¯ GuÃ­a PrÃ¡ctica: Corregir Sobreajuste en XGBoost

## ğŸ“Š SituaciÃ³n Actual

Tu modelo XGBoost tiene **SOBREAJUSTE SEVERO**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Train MAPE: 2.34% âœ… (Perfecto)            â”‚
â”‚  Test MAPE:  7.20% âŒ (Malo)                â”‚
â”‚  Ratio:      3.08x âŒ (Severo)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Soluciones (En Orden de Facilidad)

### **1ï¸âƒ£ OPCIÃ“N RÃPIDA: Early Stopping (5 minutos)**

**Idea**: Detener el training cuando el modelo deja de mejorar en datos de validaciÃ³n.

```bash
# Ejecutar con early stopping mÃ¡s agresivo
cd /Users/josefaabettdelatorrep./Desktop/PUC/College/Semestre\ 8/Taller\ de\ InvestigaciÃ³n\ Operativa\ \(Capstone\)\ \(ICS2122-1\)/Optimizacion-Casas-Ames-Iowa-Capstone-/

PYTHONPATH=. python3 src/train_xgb_es.py \
  --csv data/raw/df_final_regresion.csv \
  --target SalePrice_Present \
  --outdir models/xgb/test_early50 \
  --log_target \
  --patience 50
```

**QuÃ© pasa**: 
- El script entrena con validaciÃ³n interna
- Para cuando no hay mejora en 50 rondas
- Usa la mejor iteraciÃ³n encontrada

**Resultado esperado**: MAPE test de 6.0-6.5%

---

### **2ï¸âƒ£ OPCIÃ“N MODERADA: Reducir Complejidad (15 minutos)**

**Idea**: Usar menos Ã¡rboles y mÃ¡s regularizaciÃ³n.

Crea un nuevo archivo: `src/config_reduced.py`

```python
from config import Config

# Copia la config original y ajusta:
cfg = Config()
cfg.xgb_params = {
    "n_estimators": 800,          # â† Reducido (de 1800)
    "learning_rate": 0.025,
    "max_depth": 5,
    "min_child_weight": 10,
    "subsample": 0.6,              # â† Reducido (de 0.7)
    "colsample_bytree": 0.6,       # â† Reducido (de 0.7)
    "reg_lambda": 4.0,             # â† Aumentado (de 2.0)
    "reg_alpha": 1.0,              # â† Nuevo (agregar L1)
    "tree_method": "hist",
    "objective": "reg:squarederror",
    "n_jobs": -1,
    "random_state": 42,
}
```

Luego entrena:
```bash
PYTHONPATH=. python3 src/train_xgb_es.py \
  --csv data/raw/df_final_regresion.csv \
  --target SalePrice_Present \
  --outdir models/xgb/test_reduced \
  --log_target \
  --patience 50
```

**Resultado esperado**: MAPE test de 5.5-6.0%

---

### **3ï¸âƒ£ OPCIÃ“N EXHAUSTIVA: Grid Search (2 horas, automÃ¡tico)**

Crea: `scripts/grid_search_xgb.py`

```python
#!/usr/bin/env python3
import argparse, json, os
import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from xgboost import XGBRegressor
from src.config import Config
from src.preprocess import infer_feature_types, build_preprocessor
from src.metrics import regression_report

# ParÃ¡metros a probar
param_grid = {
    'n_estimators': [600, 900, 1200],
    'max_depth': [3, 4, 5],
    'reg_lambda': [2.0, 4.0, 6.0],
    'subsample': [0.5, 0.6, 0.7]
}

# Generar todas las combinaciones
from itertools import product
configs = [dict(zip(param_grid.keys(), values)) 
           for values in product(*param_grid.values())]

print(f"Probando {len(configs)} combinaciones...")

df = pd.read_csv("data/raw/df_final_regresion.csv")
cfg = Config()

# ... resto del cÃ³digo de CV ...
# Reportar mejor configuraciÃ³n
```

**Resultado esperado**: MAPE test de 5.0-5.5%

---

## ğŸ“‹ Checklist de ImplementaciÃ³n

### Paso 1: Prueba RÃ¡pida (Ahora, 5 min)
```bash
cd '/Users/josefaabettdelatorrep./Desktop/PUC/College/Semestre 8/Taller de InvestigaciÃ³n Operativa (Capstone) (ICS2122-1)/Optimizacion-Casas-Ames-Iowa-Capstone-/'

PYTHONPATH=. python3 src/train_xgb_es.py \
  --csv data/raw/df_final_regresion.csv \
  --target SalePrice_Present \
  --outdir models/xgb/test_quick \
  --log_target \
  --patience 50
```

âœ… **Luego:**
```bash
# Ver mÃ©tricas
cat models/xgb/test_quick/metrics.json
```

---

### Paso 2: ValidaciÃ³n (10 min despuÃ©s)
```bash
# Crear script de comparaciÃ³n
python3 << 'EOF'
import json

print("\nğŸ“Š COMPARACIÃ“N DE MODELOS\n")

# Modelo original
with open("models/xgb/completa_present_log_p2_1800_ELEGIDO/metrics.json") as f:
    original = json.load(f)

# Modelo nuevo
with open("models/xgb/test_quick/metrics.json") as f:
    nuevo = json.load(f)

print("MÃ‰TRICA                 ORIGINAL    NUEVO      MEJORA")
print("-" * 55)

mape_orig = original['test']['MAPE_pct']
mape_new = nuevo['test']['MAPE_pct']
mejora = ((mape_orig - mape_new) / mape_orig) * 100

print(f"MAPE Test            {mape_orig:7.2f}%  {mape_new:7.2f}%  {mejora:+.1f}%")

mae_orig = original['test']['MAE']
mae_new = nuevo['test']['MAE']
mejora = ((mae_orig - mae_new) / mae_orig) * 100

print(f"MAE Test             ${mae_orig:7,.0f}  ${mae_new:7,.0f}  {mejora:+.1f}%")

r2_orig = original['test']['R2']
r2_new = nuevo['test']['R2']
mejora = ((r2_new - r2_orig) / (1 - r2_orig)) * 100

print(f"RÂ² Test                {r2_orig:6.4f}   {r2_new:6.4f}   {mejora:+.1f}%")

print("\n")
EOF
```

---

## ğŸ¯ MÃ©tricas Objetivo

| MÃ©trica | Actual | Objetivo | Alcanzable |
|---------|--------|----------|-----------|
| **MAPE Test** | 7.20% | < 6.0% | âœ… SÃ­ |
| **MAE Test** | $21,224 | < $18,000 | âœ… SÃ­ |
| **Ratio MAPE** | 3.08x | < 2.0x | âœ… SÃ­ |
| **RÂ² Test** | 0.9304 | > 0.94 | âš ï¸ QuizÃ¡ |

---

## ğŸ“ Entendimiento del Problema

```
Â¿POR QUÃ‰ OCURRE EL SOBREAJUSTE?

Tienes 1800 Ã¡rboles con learning_rate=0.025
        â†“
Esto = 1800 Ã— 0.025 â‰ˆ 45 unidades de "fuerza"
        â†“
Con esa capacidad, el modelo MEMORIZA el training set
        â†“
Aprende patrones reales PERO TAMBIÃ‰N ruido especÃ­fico
        â†“
El ruido NO estÃ¡ en el test set
        â†“
Por eso test MAPE es 3x peor
```

---

## âœ… RecomendaciÃ³n Final

**COMIENZA CON LA OPCIÃ“N 1** (Early Stopping):
- â±ï¸ Toma 5 minutos
- ğŸ“Š DeberÃ­a mejorar MAPE test a ~6%
- ğŸ”§ Sin cambios de hiperparÃ¡metros

**SI NO ES SUFICIENTE**, prueba OpciÃ³n 2:
- â±ï¸ Toma 15 minutos
- ğŸ“Š DeberÃ­a mejorar MAPE test a ~5.5%
- ğŸ”§ Reduce complejidad

**SI QUIERES LO MEJOR**, usa OpciÃ³n 3:
- â±ï¸ Toma 2 horas
- ğŸ“Š DeberÃ­a alcanzar MAPE test ~5%
- ğŸ”§ BÃºsqueda exhaustiva

---

## ğŸ“ Â¿Necesitas Ayuda?

Los scripts y documentaciÃ³n estÃ¡n en:
- `ANALISIS_OVERFITTING_XGBOOST.md` - AnÃ¡lisis tÃ©cnico
- `RESUMEN_OVERFITTING_Y_SOLUCIONES.md` - Plan de acciÃ³n
- `scripts/analizar_overfitting.py` - Script de diagnÃ³stico

**GrÃ¡ficos generados:**
- `analisis/overfitting_analisis.png`
- `analisis/deterioro_metricas.png`

---

