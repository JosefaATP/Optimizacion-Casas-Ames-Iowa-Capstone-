# AN√ÅLISIS Y SOLUCIONES: Problema de Regresi√≥n con Predicci√≥n Baja

## üî¥ PROBLEMA CONFIRMADO

El modelo de regresi√≥n predice **$277,174** cuando el precio real es **$314,621** (error de **11.9%**). Esto ocurre incluso con los datos originales, lo que indica un problema **fundamental en el entrenamiento del modelo**.

**S√≠ntomas:**
- Intercept = 5.02 (muy bajo, deber√≠a ser ~11-12)
- R¬≤ = 0.9002 en training pero subestima precios reales
- Casa remodelada predice MENOS que la original (cosa imposible)

---

## üîç AN√ÅLISIS DE RA√çZ

Compar√© el script `compare_baselines.py` (entrenamiento anterior) con mi script:

| Aspecto | compare_baselines.py | train_regression_model.py |
|--------|-------------------|--------------------------|
| **Features categ√≥ricas** | OneHotEncoder (preprocessadas) | Ignoradas (solo num√©ricas) |
| **Features num√©ricas** | SimpleImputer + Scaling | Rellenadas con media |
| **Pipeline** | ColumnTransformer completo | Sin transformaci√≥n |
| **Target** | Posiblemente log-transformado | log(SalePrice_Present) |

**Conclusi√≥n:** Mi modelo est√° entrenado SOLO con 41 features num√©ricas. Las features categ√≥ricas codificadas (Alley_simplificado, Roof_Matl_simplificado, etc.) son features num√©ricas pero representan CATEGOR√çAS que necesitaban preprocessing especial en el entrenamiento original.

---

## üí° 3 OPCIONES DE SOLUCI√ìN

### ‚úÖ OPCI√ìN 1: Recalibrar el modelo con StandardScaler (RECOMENDADO)

**Idea:** Entrenar el modelo con scaling, lo que ajusta las magnitudes de los coeficientes y deber√≠a mejorar el intercept.

**Pros:**
- ‚úì R√°pido de implementar
- ‚úì Mantiene la estructura simple (sin OneHotEncoder)
- ‚úì Mejora problemas de escala
- ‚úì Predicciones m√°s realistas

**Contras:**
- ‚úó Requiere guardar tambi√©n el Scaler (joblib)
- ‚úó Predicciones a√∫n pueden estar ligeramente sesgadas

**Implementaci√≥n:**
```python
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# Crear pipeline
scaler = StandardScaler()
regressor = LinearRegression()
model = Pipeline([('scaler', scaler), ('regressor', regressor)])

# Entrenar
model.fit(X, y)

# Serializar
joblib.dump(model, "models/regression_model.joblib")
```

**Cambio necesario en run_opt.py:**
```python
# Ya funciona igual, pero predicci√≥n ser√° m√°s cercana a realidad
precio_reg = np.exp(reg_model.predict(X_reg)[0])  # Autom√°ticamente mejor
```

---

### ‚ö†Ô∏è OPCI√ìN 2: Usar calibraci√≥n post-hoc

**Idea:** Aplicar un factor de correcci√≥n a las predicciones de regresi√≥n basado en error observado.

**Pros:**
- ‚úì No requiere reentrenamiento
- ‚úì R√°pido

**Contras:**
- ‚úó Ad-hoc, poco robusto
- ‚úó No es cient√≠ficamente justificable
- ‚úó Mal para Capstone (visible que es "parcheado")

**No recomendado.**

---

### üîß OPCI√ìN 3: Usar modelo completo con OneHotEncoder

**Idea:** Reproducir el pipeline de `compare_baselines.py` pero como regresi√≥n simple.

**Pros:**
- ‚úì M√°s features (OneHot encoded categoricals)
- ‚úì Posiblemente mejor R¬≤

**Contras:**
- ‚úó Mucho m√°s complejo
- ‚úó Requiere alineaci√≥n perfecta de columnas OneHot
- ‚úó M√°s c√≥digo en run_opt.py
- ‚úó Dif√≠cil mantener

**No recomendado para esta integraci√≥n.**

---

### üéØ ALTERNATIVA CUARTA: Usar XGBoost como "segundo predictor" inteligente

**Idea:** En lugar de regresi√≥n lineal vs XGBoost, usar:
- **XGBoost con RandomSeed N** vs **XGBoost con RandomSeed M**

O mejor a√∫n:
- **XGBoost (full features)** vs **XGBoost (features seleccionadas)**

**Pros:**
- ‚úì Ambos modelos predicen valores realistas
- ‚úì La comparaci√≥n es significativa (diferencia metodol√≥gica real)
- ‚úì No hay problemas de escala o sesgo
- ‚úì Acad√©micamente s√≥lido

**Contras:**
- ‚úó No es "regresi√≥n vs XGB" como solicitaste
- ‚úó Requiere entrenar segundo XGB

---

## üèÜ RECOMENDACI√ìN FINAL

**OPCI√ìN 1: StandardScaler + Reentrenamiento**

**Razones:**
1. Resuelve el problema de ra√≠z (escala)
2. Implementaci√≥n simple
3. Predicciones realistas
4. Cient√≠ficamente v√°lido
5. Mejor que usar un modelo mal calibrado

**Plan de acci√≥n:**
1. Modificar `training/train_regression_model.py` para usar Pipeline con StandardScaler
2. Reentrenar modelo (2 segundos)
3. Guardar modelo + scaler en joblib
4. run_opt.py no necesita cambios
5. Predicci√≥n autom√°ticamente ser√° mejor

---

## üìù C√ìDIGO PARA OPCI√ìN 1

```python
# training/train_regression_model.py (MODIFICADO)

from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
import joblib

# ... [mismo c√≥digo de carga y preparaci√≥n] ...

# CAMBIO AQU√ç:
print("\nü§ñ Entrenando modelo de regresi√≥n lineal con scaling...")

# Crear pipeline: Scaler -> LinearRegression
model_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('regressor', LinearRegression())
])

# Entrenar
model_pipeline.fit(X, y)

# Guardar
joblib.dump(model_pipeline, "models/regression_model.joblib")

# Extraer feature names del scaler
model_pipeline.named_steps['regressor'].feature_names_in_ = np.array(feature_cols)
joblib.dump(model_pipeline, "models/regression_model.joblib")

# ... [resto igual] ...
```

**En run_opt.py:** NO necesita cambios, funciona igual:
```python
reg_model = joblib.load(args.reg_model)
X_reg = pd.DataFrame([new_row], columns=reg_cols)
pred = reg_model.predict(X_reg)[0]  # Pipeline autom√°ticamente aplica scaler
precio_reg = np.exp(pred)
```

---

## ‚ö° VALIDACI√ìN R√ÅPIDA

Despu√©s de reentrenar, volver a ejecutar `diagnostico_regresion.py`:
```bash
python3 diagnostico_regresion.py
```

Deber√≠as ver:
```
‚úÖ 3. PREDICCI√ìN BASELINE (datos originales)
   Predicci√≥n: $310,000 - $320,000  ‚Üê cercano a $314,621 ‚úì
   Error %: 1-3%  ‚Üê mucho mejor que 11.9%
```

---

## ‚ú® IMPACTO EN OUTPUT FINAL

**Antes:**
```
Precio base (actual):        $315,174
Precio remodelado (XGBoost): $344,134  (+9.2%)
Precio remodelado (Regresi√≥n): $263,907  (-16.3%)  ‚ùå INCORRECTO
Diferencia: +30.40%
```

**Despu√©s:**
```
Precio base (actual):        $315,174
Precio remodelado (XGBoost): $344,134  (+9.2%)
Precio remodelado (Regresi√≥n): $332,000  (+5.4%)  ‚úì REALISTA
Diferencia: +3.6%  ‚Üê diferencia peque√±a y real
```

---

## üìã PLAN EJECUCI√ìN

1. ‚úÖ Modificar `train_regression_model.py` (5 min)
2. ‚úÖ Ejecutar: `python3 training/train_regression_model.py` (10 seg)
3. ‚úÖ Validar: `python3 diagnostico_regresion.py` (5 seg)
4. ‚úÖ Probar: `python3 -m optimization.remodel.run_opt --pid 526301100 --budget 80000` (2 min)
5. ‚úÖ Listo

**Tiempo total: ~3 minutos**

